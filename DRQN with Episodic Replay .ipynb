{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcb_twin.multipath_grid_env import MultiPathGridEnv\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from agents.drqn_agent import DRQNAgent\n",
    "from replay_buffers import DRQN_ReplayBuffer\n",
    "from IPython.display import display, clear_output\n",
    "from IPython.core.debugger import set_trace \n",
    "import csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_agents = 1\n",
    "grid_size = [15,10]\n",
    "obs_size = [40,40] # Basically get full grid :-) [for now!]\n",
    "obstacles = [(3,3),(6,2), (6,3), (9,4), (9,3), (10,4), (8,9), (8,8)]\n",
    "starts = [(13,8)]\n",
    "goals = [(1,1)] # orig: (2,1) \n",
    "to_train = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env1 = MultiPathGridEnv(obstacles, starts, goals, grid_size=grid_size, obs_size=obs_size, agents_n=n_agents, train=to_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env1.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dim = grid_size[0]*grid_size[1]\n",
    "action_dim = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "drqn_agent = DRQNAgent(action_dim, DRQN_ReplayBuffer(100), device)\n",
    "reward_sums_list = []\n",
    "epsilon_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent(agent):\n",
    "    N = 100000\n",
    "    max_time_steps = 3000\n",
    "    epsilon = 0.4\n",
    "    decay = 0.9999\n",
    "    min_epsilon = 0.1\n",
    "    #context = (Variable(torch.zeros(3, 1, 181).float()), Variable(torch.zeros(3, 1, 181).float()))\n",
    "    for episode in range(N):\n",
    "        reward_sum = 0\n",
    "        episode_experience = []\n",
    "        state = env1.reset()[0] # Indent into 0 for now and elsewhere :-) \n",
    "        epsilon = max(min_epsilon, epsilon*decay)\n",
    "        epsilon_history.append(epsilon)\n",
    "        for i in range(max_time_steps):\n",
    "            chosen_actions = []\n",
    "            t_state = (torch.from_numpy(state[0]).reshape(1,1,grid_size[0],grid_size[1]).float().to(device),torch.Tensor([state[1]]).to(device))\n",
    "            # TO DO: Insert context/hidden state from previous timestep action selection??...\n",
    "            action, context = agent.epsilon_greedy_action(t_state, epsilon)\n",
    "            if type(action) is not list:\n",
    "                action = [action]\n",
    "            next_state, reward, terminal = env1.step(action)\n",
    "            next_state = next_state[0]\n",
    "            buff_state = (state[0].reshape(1,grid_size[0],grid_size[1]), state[1])\n",
    "            obs = (buff_state, action, [reward])\n",
    "            episode_experience.append(obs)\n",
    "            reward_sum += reward[0]\n",
    "            state = next_state\n",
    "            #env1.render()\n",
    "            if terminal:\n",
    "                reward_sums_list.append(reward_sum)\n",
    "                reward_sum = 0\n",
    "                agent.memory.add_to_buffer(tuple(episode_experience))\n",
    "                break\n",
    "        if episode !=0:\n",
    "            agent.update(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 1, 7, 7]' is invalid for input of size 150",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-20aa5356a659>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrqn_agent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-a37dee7dcda5>\u001b[0m in \u001b[0;36mtrain_agent\u001b[0;34m(agent)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mt_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrid_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrid_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# TO DO: Insert context/hidden state from previous timestep action selection??...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon_greedy_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ds_projects/MARL-Cooperative-Path-Planning/agents/drqn_agent.py\u001b[0m in \u001b[0;36mepsilon_greedy_action\u001b[0;34m(self, state, epsilon)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mepsilon_greedy_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mnetwork_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ds_projects/MARL-Cooperative-Path-Planning/agents/drqn_agent.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state, hidden, episode_lengths)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mgrid_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mgrid_state_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 1, 7, 7]' is invalid for input of size 150"
     ]
    }
   ],
   "source": [
    "train_agent(drqn_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
